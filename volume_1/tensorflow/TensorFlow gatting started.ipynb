{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  What is TensorFlow ?\n",
    "TensorFlow is a library for numerical computation where data flows through the graph.  Data in TensorFlow is represented by n-dimensional arrays called Tensors. Graph is made of data(Tensors) and mathematical operations. \n",
    "\n",
    "    Nodes on the graph: represent mathematical operations. \n",
    "\n",
    "    Edges on the graph: represent the Tensors that flow between operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'tensorflow' from '/home/cogknit/.virtualenvs/cogknitEnv/lib/python3.5/site-packages/tensorflow/__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph in TensorFlow\n",
    "\n",
    "Graph is the backbone of TensorFlow and every computation/operation/variables reside on the graph. Everything that happens in the code, resides on a default graph provided by TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "print(graph.get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow session\n",
    "\n",
    "A graph is used to define operations, but the operations are only run within a session. Graphs and sessions are created independently of each other. You can imagine graph to be similar to a blueprint, and a session to be similar to a construction site.\n",
    "\n",
    "Graph only defines the computations or builds the blueprint. However, there are no variables, no values unless we run the graph or part of the graph within a session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run code what you want\n",
      "Run code whatever you want\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "print(\"Run code what you want\")\n",
    "sess.close()\n",
    "\n",
    "\n",
    "#another way to to do inside the Session\n",
    "with tf.Session() as sess:\n",
    "    print(\"Run code whatever you want\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor in TensorFlow\n",
    "\n",
    "TF holds data in Tensors which are similar to numPy multi-dimensional arrays(although they are different from numPy Arrays):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a) Constants\n",
    "\n",
    "are constants whose value canâ€™t be changed. You can declare a constant like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant(5.0)\n",
    "a\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b) Variable\n",
    "are again Tensors which are like variables in any other language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n"
     ]
    }
   ],
   "source": [
    "b=tf.Variable(5.0,name=\"test_var\")\n",
    "b\n",
    "#They need to be separately initialized by init op.\n",
    "init_op=tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholders:\n",
    "are tensors which are waiting to be initialized/fed. Placeholders are used for training data which is only fed when the code is actually run inside a session. What is fed to Placeholder is called feed_dict. Feed_dict are key value pairs for holding data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    }
   ],
   "source": [
    "c=tf.placeholder(\"float\")\n",
    "d=tf.placeholder(\"float\")\n",
    "y=tf.multiply(c,d)\n",
    "\n",
    " # Earlier this used to be tf.mul which has changed with Tensorflow 1.0\n",
    " \n",
    " # Typically we load feed_dict from somewhere else, \n",
    " # may be reading from a training data folder etc\n",
    " # For simplicity, we have put values in feed_dict here\n",
    "feed_dict={c:2,d:3}\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(y,feed_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device in TensorFlow\n",
    "TensorFlow has very strong in-built capabilites to run your code on a gpu or a cpu or a cluster of gpu etc. It provides you options to select the device you want to run your code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "x=tf.Variable([10,20,30,40,50,60],name='t')\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(tf.reduce_mean(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Exercise\n",
    "\n",
    "Problem statement: In linear regression, you get a lot of data-points and try to fit them on a straight line. For this example, we will create 100 datapoints and try to fit them into a line\n",
    "\n",
    "### a) Creating training data\n",
    "trainX has values between -1 and 1, and trainY has 3 times the trainX and some randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "trainX=np.linspace(-1,1,101)\n",
    "trainY=3*trainX + np.random.randn(*trainX.shape)*0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Placeholders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=tf.placeholder(\"float\")\n",
    "Y=tf.placeholder(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Modeling\n",
    "\n",
    "Linear regression model :\n",
    "y_model=w*x ,\n",
    "Lets initialize w to 0 and \n",
    "cost=(Y-y_model)^2\n",
    "\n",
    "We are going to define the training operation as changing the values using GradientDescentOptimizer to minimize cost with a learning rate of 0.01. Later we will run this training operation in a loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=tf.Variable(0.0,name=\"weights\")\n",
    "y_model = tf.multiply(X,w)\n",
    "\n",
    "cost= (tf.pow(Y-y_model,2))\n",
    "train_op = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Training:\n",
    "we have only defined the graph. No computation has happened.\n",
    "\n",
    "None of the TensorFlow variables have any value. In order to run this graph, we need to create a Session and run. Before that we need to create the init_op to initialize all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.95512\n"
     ]
    }
   ],
   "source": [
    "# Creating init to initdialize all variables\n",
    "init=tf.global_variables_initializer() \n",
    "# labeledData=zip(trainX,trainY)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(1000):\n",
    "        for (x,y) in zip(trainX,trainY):\n",
    "            sess.run(train_op,feed_dict={X:x,Y:y})\n",
    "    print(sess.run(w))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. What is a TensorFlow model\n",
    "After you have trained a neural network, you would want to save it for future use and deploying to production. So, what is a Tensorflow model? Tensorflow model primarily contains the network design or graph and values of the network parameters that we have trained.\n",
    "### a) Meta graph\n",
    "This is a protocol buffer which saves the complete TensorFlow graph\n",
    "### b) Checkpoin file:\n",
    "this is a binary file which contains all the values of the weights, biases,gredients and all the other vaiables saved.\n",
    "\n",
    "#### mymodel.data-00000-of-00001\n",
    "#### mymodel.index\n",
    "\n",
    "Here .data file is the file that contains our training variables.\n",
    "Tensorflow also has a file named checkpoint which simply keeps a record of latest checkpoint files saved.\n",
    "\n",
    "# 2. Saving a Tensorflow model\n",
    "Once you see that the network has converged, you can stop the training manually or you will run the training for fixed number of epochs. After the training is done, we want to save all the variables and network graph to a file for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my_test_model'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "w1 = tf.Variable(tf.random_normal(shape=[2]), name='w1')\n",
    "w2 = tf.Variable(tf.random_normal(shape=[5]), name='w2')\n",
    "saver = tf.train.Saver()\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver.save(sess, 'my_test_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing a pre-trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_test_model\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('my_test_model.meta')\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint('./'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./my_test_model\n",
      "[ 2.16286111  0.05795197]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "with tf.Session() as sess:    \n",
    "    saver = tf.train.import_meta_graph('my_test_model.meta')\n",
    "    saver.restore(sess,tf.train.latest_checkpoint('./'))\n",
    "    print(sess.run('w1:0'))\n",
    "##Model has been restored. Above statement will print the saved value of w1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (cogknitEnv)",
   "language": "python",
   "name": "cogknitenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
